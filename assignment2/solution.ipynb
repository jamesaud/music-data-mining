{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "\n",
    "a) MAE for user based collaborative filtering: 1.705\n",
    "\n",
    "b) MAE for item based collaborative filtering: 2.105\n",
    "\n",
    "\n",
    "# Question 2\n",
    "\n",
    "a) For User Based\n",
    "   Precision: .95\n",
    "   Recall: .57\n",
    "   MAP: 0.5635416666666666\n",
    "   nDCG: 0.9918882873518092\n",
    "\n",
    "\n",
    "b) For Item Based\n",
    "   Precision: 0\n",
    "   Recall: 0\n",
    "   MAP: 0\n",
    "   nDCG: 0\n",
    "   \n",
    "   My item based implementation did not yield any scores above 4.0. Therefore, the scores all compute 0.\n",
    "   \n",
    "   \n",
    "notes: some code is based on the tutorial: https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/\n",
    "\n",
    "and ndcg_at_k implemented from: https://gist.github.com/bwhite/3726239\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "workdir = os.getcwd()\n",
    "def film_data():\n",
    "    with open(os.path.join(workdir, 'selected_films.txt')) as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    lines = map(str.strip, lines)\n",
    "    lines = [[line[:4], line[5:]] for line in lines]\n",
    "    lines = [[int(line[0])] + [line[1]] + [i] for i, line in enumerate(lines, 1)]   \n",
    "    lines = list(lines)\n",
    "    df = pd.DataFrame(lines, columns=['Year', 'Title', 'Index'])\n",
    "    return df\n",
    "\n",
    "def user_data():\n",
    "    with open(os.path.join(workdir, 'm_u_ratings.txt')) as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    lines = map(str.strip, lines)\n",
    "    lines = [map(int, line.split()) for line in lines]\n",
    "    df = pd.DataFrame(lines, columns=['MovieID', 'UserID', 'Rating'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2897</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6549</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>389</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>287</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8867</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID  UserID  Rating\n",
       "0        1    2897       3\n",
       "1        1    6549       4\n",
       "2        1     389       4\n",
       "3        1     287       3\n",
       "4        1    8867       3"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = user_data()\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Miss Congeniality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>Independence Day</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>The Patriot</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>The Day After Tomorrow</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                                              Title  Index\n",
       "0  2000                                  Miss Congeniality      1\n",
       "1  1996                                   Independence Day      2\n",
       "2  2000                                        The Patriot      3\n",
       "3  2004                             The Day After Tomorrow      4\n",
       "4  2003  Pirates of the Caribbean: The Curse of the Bla...      5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films = film_data()\n",
    "films.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(ratings, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2434915</th>\n",
       "      <td>300</td>\n",
       "      <td>3409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750030</th>\n",
       "      <td>1949</td>\n",
       "      <td>3541</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6906852</th>\n",
       "      <td>1090</td>\n",
       "      <td>3045</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8937814</th>\n",
       "      <td>1647</td>\n",
       "      <td>845</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220134</th>\n",
       "      <td>739</td>\n",
       "      <td>9261</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MovieID  UserID  Rating\n",
       "2434915      300    3409       1\n",
       "9750030     1949    3541       4\n",
       "6906852     1090    3045       3\n",
       "8937814     1647     845       3\n",
       "5220134      739    9261       4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = max(ratings.UserID.unique())\n",
    "n_items = max(ratings.MovieID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_data_matrix(train):\n",
    "\n",
    "    data_matrix = np.zeros((n_users, n_items))\n",
    "\n",
    "    for line in train.itertuples():\n",
    "        rating = line.Rating\n",
    "        data_matrix[line.UserID-1, line.MovieID-1] = rating\n",
    "    return data_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances \n",
    "\n",
    "def get_similarities(data_matrix):\n",
    "    user_similarity = pairwise_distances(data_matrix, metric='cosine')\n",
    "    item_similarity = pairwise_distances(data_matrix.T, metric='cosine')\n",
    "    return user_similarity, item_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function based on tutorial https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/\n",
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "def get_y_pred(prediction, test):\n",
    "\n",
    "    y_pred = []\n",
    "    for i, movieID, userID, Rating in test.itertuples():\n",
    "        rating = prediction[userID-1][movieID-1]\n",
    "        y_pred.append(rating)\n",
    "    return y_pred\n",
    "\n",
    "def predict_mse(prediction, test):\n",
    "    y_pred = get_y_pred(prediction, test)\n",
    "    y_true = test['Rating'].values\n",
    "    return mse(y_true, y_pred, sample_weight=None, multioutput='uniform_average')\n",
    "\n",
    "\n",
    "def pred_mse(train, test):\n",
    "    \"\"\" returns mse for user_prediction and item_prediction \"\"\"\n",
    "    data_matrix = calc_data_matrix(train)\n",
    "    user_similarity, item_similarity = get_similarities(data_matrix)\n",
    "    \n",
    "    user_prediction = predict(data_matrix, user_similarity, type='user')\n",
    "    item_prediction = predict(data_matrix, item_similarity, type='item')\n",
    "\n",
    "    mse_user = predict_mse(user_prediction, test) \n",
    "    mse_item = predict_mse(item_prediction, test)\n",
    "\n",
    "    return mse_user, mse_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mse\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "mse_user_error = 0\n",
    "mse_item_error = 0\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(ratings):\n",
    "    i+=1\n",
    "    train, test = ratings.iloc[train_index], ratings.iloc[test_index] \n",
    "    train, test = train_test_split(ratings, test_size=0.1)\n",
    "    mse_user, mse_item = pred_mse(train, test)\n",
    "    mse_user_error += mse_user\n",
    "    mse_item_error += mse_item\n",
    "\n",
    "mse_user_error /= i\n",
    "mse_item_error /= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7061068800781376, 2.1062108905575863)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_user_error, mse_item_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from functools import reduce\n",
    "\n",
    "# Selected 100 users ratings, \n",
    "users = [random.randint(1, n_users) for _ in range(100)]\n",
    "\n",
    "# Select 10% of each user's ratings \n",
    "test = [ratings[ratings.UserID==userid].sample(frac=.1) for userid in users]\n",
    "test = pd.concat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the test from the training set\n",
    "train = ratings.drop(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = calc_data_matrix(train)\n",
    "user_similarity, item_similarity = get_similarities(data_matrix)\n",
    "\n",
    "user_prediction = predict(data_matrix, user_similarity, type='user')\n",
    "item_prediction = predict(data_matrix, item_similarity, type='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4916667</th>\n",
       "      <td>683</td>\n",
       "      <td>8550</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269502</th>\n",
       "      <td>1178</td>\n",
       "      <td>8550</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345843</th>\n",
       "      <td>160</td>\n",
       "      <td>8550</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310131</th>\n",
       "      <td>155</td>\n",
       "      <td>8550</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013318</th>\n",
       "      <td>700</td>\n",
       "      <td>8550</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MovieID  UserID  Rating\n",
       "4916667      683    8550       3\n",
       "7269502     1178    8550       4\n",
       "1345843      160    8550       2\n",
       "1310131      155    8550       5\n",
       "5013318      700    8550       4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def movie_ids_for_user(userID):\n",
    "    return test[test.UserID == userID].MovieID.values\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "    \n",
    "def datamatrix_to_df(data_matrix):\n",
    "    return pd.DataFrame(data_matrix)\n",
    "    \n",
    "\n",
    "def user_movie_mask(userID, predictions):\n",
    "    movie_ids = movie_ids_for_user(userID)\n",
    "    mask = (predictions == predictions) & (predictions.columns.isin(movie_ids))\n",
    "    mask = mask[mask.index==userID]\n",
    "    return mask\n",
    "\n",
    "\n",
    "def users_mask(predictions):\n",
    "    masks = [user_movie_mask(userID, predictions) for userID in set(test.UserID.values)]\n",
    "    return masks\n",
    "\n",
    "\n",
    "def get_predictions(prediction):\n",
    "    df = datamatrix_to_df(prediction)\n",
    "    df.index = np.arange(1, len(df)+1)\n",
    "    df.columns = np.arange(1, len(df.columns.values) + 1)\n",
    "\n",
    "    # Predcitions for the 100 users\n",
    "    predictions = df[df.index.isin(test.UserID.values)]\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_ratings_over(predictions, over=4):\n",
    "    masks = users_mask(predictions)\n",
    "    masked = pd.DataFrame()\n",
    "\n",
    "    for mask in masks:\n",
    "        index = mask.index.values[0]\n",
    "        df = predictions[predictions.index == index].mask(~mask)\n",
    "        masked = pd.concat([masked, df])\n",
    "    \n",
    "    return masked[masked > over]\n",
    "\n",
    "test_ratings_users = get_predictions(user_prediction)\n",
    "test_ratings_items = get_predictions(item_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ratings_users = get_ratings_over(test_ratings_users, 4)\n",
    "pred_ratings_items = get_ratings_over(test_ratings_items, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(rating_df):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    true_ratings = []\n",
    "    for userID, movie_ratings in rating_df.iterrows():\n",
    "        user_ratings_true = ratings[ratings.UserID == userID]\n",
    "        pred = []\n",
    "        true = []\n",
    "        for movieID, rating in enumerate(movie_ratings, 1):\n",
    "            if np.isnan(rating):\n",
    "                continue\n",
    "            true.append(user_ratings_true[user_ratings_true.MovieID == movieID].Rating.values[0])\n",
    "            pred.append(rating)\n",
    "        \n",
    "        y_true.append(true)\n",
    "        y_pred.append(pred)\n",
    "        true_ratings.append(true_ratings_above(userID))\n",
    "        \n",
    "    return y_true, y_pred, true_ratings\n",
    "        \n",
    "def true_ratings_above(userID, threshold=4):\n",
    "    return sum(test[test.UserID == userID].Rating.values >= threshold)\n",
    "    \n",
    "y_true, y_pred, true_ratings = test_split(pred_ratings_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision: recommended items / relevant recommended items\n",
    "# Recall: recommened items / total # relevant items\n",
    "\n",
    "def calc_precision(y_true, y_pred, total_true):\n",
    "    precision = 0\n",
    "    for true, pred, total in zip(y_true, y_pred, total_true):\n",
    "        wrong = list(filter(lambda x: x < 4, true))\n",
    "\n",
    "        if len(pred) == 0 and len(true) == 0:\n",
    "            precision += 1\n",
    "            continue\n",
    "        try:\n",
    "            precision += (len(pred) - len(wrong)) / len(pred) \n",
    "        except Exception:\n",
    "            precision += 0\n",
    "            \n",
    "    return precision/len(total_true)\n",
    "\n",
    "def calc_recall(y_true, y_pred, total_true):\n",
    "    total = 0\n",
    "    for pred, total in zip(y_pred, total_true):\n",
    "        total += len(pred) / total\n",
    "    return total / len(total_true)\n",
    "\n",
    "prec = calc_precision(y_true, y_pred, true_ratings)\n",
    "recall = calc_recall(y_true, y_pred, true_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9549166666666667, 0.57)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audretjm/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5635416666666666"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def compute_map_scores(y_true, y_pred):\n",
    "    avg = 0\n",
    "    i = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if len(true) == 0 or len(pred)==0: continue\n",
    "        true_wrong = [True if x < 4 else False for x in true]\n",
    "        pred = [1 for _ in pred]\n",
    "        score = average_precision_score(true_wrong, [1 for _ in pred])\n",
    "        if np.isnan(score):\n",
    "            continue\n",
    "        avg+=score\n",
    "        i+=1\n",
    "    return avg / i\n",
    "\n",
    "\n",
    "score = compute_map_scores(y_true, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918882873518092"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_ndcg_scores(y_true, y_pred):\n",
    "    avg = 0\n",
    "    i = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        relevance = [1 - abs(a-b)/5 for a,b in zip(true, pred)]\n",
    "        if not relevance:\n",
    "            continue\n",
    "        i += 1\n",
    "        score = ndcg_at_k(relevance, k=len(relevance))\n",
    "        avg += score\n",
    "    return avg / i\n",
    "\n",
    "score = compute_ndcg_scores(y_true, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from: https://gist.github.com/bwhite/3726239 for ndcg@k ratings\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def dcg_at_k(r, k, method=0):\n",
    "   \n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
