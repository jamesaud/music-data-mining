{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need:\n",
    "\n",
    "\n",
    "1. Audio Features\n",
    "2. Lyrical Features  (emotion, bag of words tfidf)\n",
    "3. Page Ranked Artist (for recommendaiton)\n",
    "4. Look at similarity of songs to see where other songs ranked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "\n",
    "# DB CONFIG\n",
    "client = MongoClient('mongo', 27017)\n",
    "db = client.music_db\n",
    "COLLECTION = db['part5-hot100-songs']\n",
    "\n",
    "\n",
    "def get_songs(collection):\n",
    "    return list(collection.find())\n",
    "\n",
    "def has_spotify(song):\n",
    "    return song.get('spotify', {}).get('audio_features')\n",
    "\n",
    "def has_lyrics(song):\n",
    "    if not song.get('lyrics'):\n",
    "        return False\n",
    "    \n",
    "    if song.get('lyrics') == 'null':\n",
    "        return False\n",
    "\n",
    "    if song.get('lyrics').get('error'):\n",
    "        return False\n",
    "    \n",
    "    if not song.get('tokens'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "SONGS = get_songs(COLLECTION)\n",
    "songs = list(filter(has_lyrics, filter(has_spotify, SONGS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 80)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = [song['peakPos'] for song in songs]\n",
    "plt.hist(pos)\n",
    "\n",
    "from collections import Counter\n",
    "Counter(pos)[1], Counter(pos)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "def to_df(songs):\n",
    "    df = pd.DataFrame(songs)\n",
    "    df = df.drop(columns=['_id', 'id', 'identifier', 'lyrics', 'genre', 'isNew', 'lastPos', 'rank', 'weeks', 'track_href', 'type', 'uri', 'spotify', 'analysis_url'])\n",
    "    df['lyrics_length'] = df['raw_lyrics'].apply(lambda lyrics: len(\"\".join(lyrics.split('\\n'))))\n",
    "    return df\n",
    "    \n",
    "df = to_df(songs)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(df['peakPos'])\n",
    "X = df.drop(['peakPos', 'artist', 'raw_lyrics', 'title', 'tokens'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def vectorize_lyrics(songs):\n",
    "    lyrics_list = [\" \".join(song['tokens']) for song in songs]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(lyrics_list)\n",
    "    tfidf_array = tfidf_matrix.toarray()\n",
    "    \n",
    "    for vector, song in zip(tfidf_array, songs):\n",
    "        song['tfidf'] = vector\n",
    "    \n",
    "    return tfidf_matrix\n",
    "\n",
    "    \n",
    "def vectorize_df_lyrics(df):\n",
    "    lyrics_df = df['tokens'].apply(\" \".join).values\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(lyrics_df)    \n",
    "    return tfidf_matrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorize_lyrics(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "tfidf_distances = pairwise_distances(tfidf_matrix, metric=\"cosine\")\n",
    "distances_features = pairwise_distances(X, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  \n",
    "y_true = y_test.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "\n",
    "print()\n",
    "\n",
    "def scale(similarity):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(similarity.reshape(-1, 1))\n",
    "    similarity = scaler.transform(similarity.reshape(-1, 1))  \n",
    "    return similarity.reshape(-1)\n",
    "\n",
    "def similarity_rank():\n",
    "    return\n",
    "\n",
    "def comute_distance_rank_unweighted(distances, train_df, amount=1000):\n",
    "    \"\"\" Weight by the ranking value\"\"\"\n",
    "    \"\"\" oututs list of ranks according to similarity of songs\"\"\"\n",
    "    indexes = train_df.index.values\n",
    "    index_set = set(indexes)\n",
    "    Osition = lambda index: train_df.loc[index].peakPos\n",
    "    distances = copy.deepcopy(distances)\n",
    "    rankings = []\n",
    "    \n",
    "    x = 1\n",
    "    for i in indexes:\n",
    "        x+=1\n",
    "        print(x, '/', len(indexes))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        rank = Osition(i)\n",
    "        similarities = distances[i]\n",
    "        similarities[i] = 1\n",
    "        \n",
    "        similar = [item for item in sorted(enumerate(similarities), key=itemgetter(1)) if item[0] in index_set][:amount]\n",
    "        \n",
    "        indxs = list(map(itemgetter(0), similar)) \n",
    "        ranks = np.array([train_df.loc[index].peakPos for index in indxs])  # Do rank * weights\n",
    "        rank = np.mean(ranks)\n",
    "        rankings.append(rank)\n",
    "        \n",
    "    return rankings\n",
    "\n",
    "def comute_distance_rank(distances, train_df, amount=1000, normalize=True):\n",
    "    \"\"\" Weight by the ranking value\"\"\"\n",
    "    \"\"\" oututs list of ranks according to similarity of songs\"\"\"\n",
    "    index_range = train_df.index.values\n",
    "    index_set = set(index_range)\n",
    "    Osition = lambda index: train_df.loc[index].peakPos\n",
    "    distances = copy.deepcopy(distances)\n",
    "    rankings = []\n",
    "    \n",
    "    x = 0\n",
    "    for i in index_range:\n",
    "        x+=1\n",
    "        print(x, '/', len(index_range))\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        rank = Osition(i)\n",
    "        similarities = distances[i]\n",
    "        \n",
    "        if normalize:\n",
    "            similarities = scale(similarities)\n",
    "\n",
    "        similarities[i] = 1\n",
    "        \n",
    "        similar = [item for item in sorted(enumerate(similarities), key=itemgetter(1)) if item[0] in index_set][:amount]\n",
    "        dist = np.array(list(map(itemgetter(1), similar)))\n",
    "        \n",
    "        if not normalize:\n",
    "            dist = 1 - dist     # Weight by 1 - distance\n",
    "\n",
    "        weights = dist / sum(dist)\n",
    "                \n",
    "        indexes = list(map(itemgetter(0), similar)) \n",
    "        ranks = np.array([train_df.loc[index].peakPos for index in indexes])  # Do rank * weights\n",
    "        rank = sum(ranks * weights)\n",
    "        rankings.append(rank)\n",
    "        \n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1784 / 3268\n"
     ]
    }
   ],
   "source": [
    "train_tfidf_ranks = comute_distance_rank(tfidf_distances, y_train, 400) # 500 best aram\n",
    "test_tfidf_ranks = comute_distance_rank(tfidf_distances, y_test, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Similarity Rank'] = train_tfidf_ranks\n",
    "X_train['Similarity Rank'] = X_train['Similarity Rank'].fillna(X_train['Similarity Rank'].mean())\n",
    "\n",
    "X_test['Similarity Rank'] = test_tfidf_ranks\n",
    "X_test['Similarity Rank'] = X_test['Similarity Rank'].fillna(X_test['Similarity Rank'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_ranks = comute_distance_rank(distances_features, y_train, 100)\n",
    "test_feature_ranks = comute_distance_rank(distances_features, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Feature Rank'] = train_feature_ranks\n",
    "X_test['Feature Rank'] = test_feature_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def rank_correlation(X_train, y_train, column,  title=\"\"):\n",
    "    guessed = X_train[column].values\n",
    "    true = y_train.peakPos.values\n",
    "    \n",
    "    acc = defaultdict(list)\n",
    "    \n",
    "    for x, y in zip(true, guessed):\n",
    "        acc[x].append(y)\n",
    "    \n",
    "    x, y = [], []\n",
    "    for rank, guesses in sorted(acc.items()):\n",
    "        x.append(rank)\n",
    "        y.append(np.mean(guesses))\n",
    "    \n",
    "    plt.plot(x, y, 'bo')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "rank_correlation(X_train, y_train, column = 'Similarity Rank', title='500 Nearest Lyric Similarity Ranks')\n",
    "rank_correlation(X_train, y_train, column = 'Feature Rank', title='100 Nearest Audio Feature Similarity Ranks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_index(indexes, tfidf_matrix):\n",
    "    return np.vstack([tfidf_matrix[index].toarray() for index in indexes])\n",
    "\n",
    "def distance_index(indexes, distances):\n",
    "    return np.vstack([distances[index] for index in indexes])\n",
    "\n",
    "\n",
    "tfidf_mat_X_train = tfidf_index(X_train.index.values, tfidf_matrix)\n",
    "tfidf_mat_X_test = tfidf_index(X_test.index.values, tfidf_matrix)\n",
    "\n",
    "distance_X_train = distance_index(X_train.index.values, tfidf_distances)\n",
    "distance_X_test = distance_index(X_test.index.values, tfidf_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_norm = scaler.transform(X_train)  \n",
    "X_test_norm = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def combine_features(tfidf_matrix_train, distances, train_features):\n",
    "    combined_matrix = []\n",
    "    for tfidf, distance, features in zip(tfidf_matrix_train, distances, train_features):\n",
    "        combined = np.hstack([tfidf, features])  #features, tfidf, distance, \n",
    "        combined_matrix.append(combined)\n",
    "    return np.vstack(combined_matrix)\n",
    "\n",
    "_combined_X_train = combine_features(tfidf_mat_X_train, distance_X_train, X_train_norm)\n",
    "_combined_X_test = combine_features(tfidf_mat_X_test, distance_X_test, X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_X_train = _combined_X_train\n",
    "combined_X_test = _combined_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions(y_true, y_pred):\n",
    "    x, y = [], []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        diff = abs(true - pred)\n",
    "        \n",
    "    length = len(y_true)\n",
    "    plt.plot(y_true, 'bo')\n",
    "    plt.plot(y_pred, 'ro')\n",
    "    \n",
    "    \n",
    "def plot_sorted_predictions(y_true, y_pred):\n",
    "    true, pred = zip(*sorted(zip(y_true, y_pred)))\n",
    "    plt.plot(true, pred, 'bo')\n",
    "\n",
    "\n",
    "def run_model(model, train=False):\n",
    "\n",
    "    model.fit(X_train_norm, y_train.values.reshape(-1))\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_norm)\n",
    "    y_pred = [min(pred, 100) for pred in y_pred]\n",
    "    print(\"Error:\", mse(y_true, y_pred))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plot_predictions(y_true, y_pred)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def find_avg_guess_per_rank(y_true, y_pred):\n",
    "    buckets = defaultdict(lambda: [])\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        buckets[true].append(pred)\n",
    "    return buckets\n",
    "\n",
    "\n",
    "def plot_avg_guesses(y_true, y_pred):\n",
    "    guesses = find_avg_guess_per_rank(y_true, y_pred)\n",
    "    plt.plot(sorted(guesses.keys()), [np.mean(guesses[i]) for i in sorted(guesses.keys())])\n",
    "    return guesses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "shape = combined_X_train.shape\n",
    "#input_shape=(17830,)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(combined_X_train, y_train, batch_size=256, epochs=25, verbose=True, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "\n",
    "y_pred = model.predict(combined_X_test).reshape(-1)\n",
    "y_true = y_test.values.reshape(-1)\n",
    "\n",
    "def print_predictions(y_pred, y_true):\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        print(true, int(pred))\n",
    "        \n",
    "\n",
    "#print_predictions(y_pred, y_true)\n",
    "print(\"Error:\", mse(y_true, y_pred))\n",
    "plot_sorted_predictions(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_guesses(y_true, y_pred, error=False):\n",
    "    guesses = find_avg_guess_per_rank(y_true, y_pred)\n",
    "    x = sorted(guesses.keys())\n",
    "    y = [np.mean(guesses[i]) for i in x]\n",
    "    yerr = [np.std(guesses[i]) for i in x]\n",
    "    plt.plot(x, y, 'bo')\n",
    "    plt.title(\"Guessed Rank vs True Rank\")\n",
    "    plt.ylabel(\"Average Guessed Rank\")\n",
    "    plt.xlabel(\"True Rank\")\n",
    "    if error:\n",
    "        plt.errorbar(x, y, yerr=yerr)\n",
    "    plt.show()\n",
    "\n",
    "    return guesses\n",
    "\n",
    "guesses = plot_avg_guesses(y_true, y_pred)\n",
    "guesses = plot_avg_guesses(y_true, y_pred, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def baseline(y_test):\n",
    "    mean = y_test.peakPos.values.mean()\n",
    "    guesses = [mean] * len(y_test) \n",
    "    return mse(y_test, guesses)\n",
    "\n",
    "baseline(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "\n",
    "def guess_threshold(y_true, y_pred, val=36, low_threshold=20, high_threshold=80):\n",
    "    guesses = find_avg_guess_per_rank(y_true, y_pred)\n",
    "\n",
    "    evaluation = defaultdict(list)\n",
    "    for pos, guesses in guesses.items():\n",
    "        if high_threshold > pos > low_threshold:\n",
    "            continue\n",
    "            \n",
    "        for guess in guesses:\n",
    "            if pos <= low_threshold:\n",
    "                evaluation[pos].append(guess < val)\n",
    "                    \n",
    "            if pos >= high_threshold:\n",
    "                evaluation[pos].append( guess > val)\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def error_fn(val):\n",
    "    return (1 + val) ** 2\n",
    "\n",
    "def evaluate_guesses(val, y_true, y_pred, low_threshold=10, high_threshold=91):\n",
    "    evaluation = guess_threshold(y_true, y_pred, val, low_threshold, high_threshold)\n",
    "\n",
    "    low_avg = 0\n",
    "    high_avg = 0\n",
    "    \n",
    "    for pos, vals in evaluation.items():\n",
    "        correct = sum(vals) / len(vals) \n",
    "        err = error_fn(correct)\n",
    "        if pos <= low_threshold:\n",
    "            low_avg += correct\n",
    "        else:\n",
    "            high_avg += correct            \n",
    "        \n",
    "    num_high = 101 - high_threshold\n",
    "    num_low = low_threshold\n",
    "    total = num_high + num_low\n",
    "\n",
    "    low_avg /= num_low    \n",
    "    high_avg /= num_high\n",
    "                        \n",
    "    avg = (low_avg + high_avg) / 2\n",
    "    return avg\n",
    "\n",
    "\n",
    "def optimize(y_true, y_pred, low_threshold=10, high_threshold=90):\n",
    "    vals = np.linspace(30, 60, 200)\n",
    "    \n",
    "    param, maxi = 0, -1\n",
    "    \n",
    "    x, y = [], []\n",
    "    for i in vals:\n",
    "        acc = evaluate_guesses(i, y_true, y_pred, low_threshold, high_threshold)\n",
    "        x.append(i)\n",
    "        y.append(acc)\n",
    "\n",
    "        if acc > maxi:\n",
    "            param = i\n",
    "            maxi = acc\n",
    "            \n",
    "    return param, maxi, [x, y]\n",
    "    \n",
    "    \n",
    "def plot_thresholds(y_true, y_pred):\n",
    "    x, y = [], []\n",
    "    \n",
    "    \n",
    "    for i in range(1, 50, 1):\n",
    "        param, accuracy, _ = optimize(y_true, y_pred, i, high_threshold=101-i)\n",
    "        x.append(i)\n",
    "        y.append(accuracy)\n",
    "    \n",
    "    plt.plot(x, y)\n",
    "    \n",
    "    plt.title(\"Dyanmic Threshold ([10, 90], [20, 80], ...)\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.show()\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def plot_static_thresholds(y_true, y_pred, static_upper=90):\n",
    "    x, y = [], []\n",
    "\n",
    "    \n",
    "    for i in range(1, 50, 1):\n",
    "        param, accuracy, _ = optimize(y_true, y_pred, i, high_threshold=static_upper)\n",
    "        x.append(i)\n",
    "        y.append(accuracy)\n",
    "    \n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"Static Threshold ([10, {static_upper}], [20, {static_upper}], ...)\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Accuracy\")    \n",
    "    plt.show()\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def plot_optimal_param(y_true, y_pred, low_threshold=10, high_threshold=90):\n",
    "    param, acc, [x, y] = optimize(y_true, y_pred, low_threshold, high_threshold)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"Cutoff Accuracy for Threshold [{low_threshold}, {high_threshold}]\")\n",
    "    plt.xlabel(\"Cutoff Value\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def accuracy_per_position(guess_dict):\n",
    "    correct = {}\n",
    "    for rank, guesses in guess_dict.items():\n",
    "        correct[rank] = sum(guesses) / len(guesses)\n",
    "    return correct\n",
    "\n",
    "def plot_accuracy_per_position(y_true, y_pred, low=50, high=51):\n",
    "    param, acc, _ = optimize(y_true, y_pred, low, high)\n",
    "    guesses = guess_threshold(y_true, y_pred, param, low, high)\n",
    "    correct = accuracy_per_position(guesses)\n",
    "    x, y = zip(*sorted(correct.items()))\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(f\"Accuracy of {int(acc*100)}% for cutoff value {int(param)}, threshold [{low}, {high}]\")\n",
    "    plt.show()\n",
    "\n",
    "plot_avg_guesses(y_true, y_pred)\n",
    "plot_optimal_param(y_true, y_pred, 10, 90)\n",
    "plot_thresholds(y_true, y_pred)\n",
    "plot_static_thresholds(y_true, y_pred, static_upper=90)\n",
    "plot_accuracy_per_position(y_true, y_pred)\n",
    "plot_accuracy_per_position(y_true, y_pred, 10, 90)\n",
    "\n",
    "# # Multiple ranking by how similar, tae the average, make a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recision recall for to 10 vs bottom 90 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR() \n",
    "y_pred = run_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = plot_avg_guesses(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
